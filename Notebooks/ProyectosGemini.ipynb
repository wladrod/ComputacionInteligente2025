{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75746946-a4a7-480e-b10c-1ac4dfdf0361",
   "metadata": {},
   "source": [
    "# Propuestas Detalladas de Proyectos Finales para el Curso de Grandes Modelos de Lenguaje\n",
    "\n",
    "A continuación se detallan 10 propuestas de proyectos finales, diseñados para que los estudiantes apliquen los conocimientos adquiridos en el curso, con especial énfasis en RAG (Generación Aumentada por Recuperación) y Sistemas Agenciales.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Agente de Investigación Temática\n",
    "\n",
    "*   **Descripción Detallada:** El estudiante creará un agente que recibe un tema amplio de investigación (ej. \"Impacto de la IA en el mercado laboral\"). El agente, guiado por un LLM, primero descompondrá el tema en 3-5 subpreguntas clave (ej. \"¿Qué sectores son más susceptibles?\", \"¿Qué nuevas habilidades se demandan?\", \"¿Existen estudios sobre la creación neta de empleo?\"). Luego, para cada subpregunta, utilizará un sistema RAG para buscar información relevante en un corpus predefinido (ej. una colección de artículos académicos en PDF, páginas web guardadas o una base de datos de noticias). Finalmente, el agente usará el LLM para sintetizar la información recuperada para cada subpregunta y presentará un resumen estructurado del tema original, citando (idealmente) las fuentes de información utilizadas.\n",
    "*   **Objetivos Principales:** Demostrar la capacidad de usar LLMs para la planificación (descomposición de tareas), implementar RAG para la búsqueda focalizada en un corpus, y usar LLMs para la síntesis de información de múltiples fuentes.\n",
    "*   **Componentes Clave del Curso Aplicados:** Ingeniería de Prompts (descomposición, síntesis), RAG (indexación, recuperación), Arquitectura de LLM (comprensión de capacidades), Sistemas Agenciales (flujo básico de planificación y ejecución).\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, LangChain/LlamaIndex, Vector DB (FAISS, ChromaDB, Pinecone), LLM API (OpenAI, Hugging Face Hub, etc.), biblioteca para leer PDFs (PyPDF2).\n",
    "*   **Desafíos Potenciales:** Calidad de la descomposición del tema, relevancia y precisión de la información recuperada por RAG, coherencia y objetividad de la síntesis final.\n",
    "*   **Entregable Sugerido:** Código fuente del agente, un pequeño corpus documental de ejemplo, un informe breve describiendo la arquitectura y los resultados, y una demo (video o en vivo).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Asistente de Soporte Técnico Básico con RAG\n",
    "\n",
    "*   **Descripción Detallada:** Se desarrollará un chatbot que actúa como asistente de soporte técnico de primer nivel. Utilizará RAG sobre una base de conocimientos específica (ej. FAQs, manuales de un producto de software o hardware simplificado). Cuando un usuario haga una pregunta (ej. \"¿Cómo reseteo mi contraseña?\"), el sistema buscará en la base de conocimientos usando RAG. Si encuentra información relevante, el LLM la formateará en una respuesta clara. Si RAG no devuelve resultados útiles o el usuario indica que la respuesta no funcionó, el agente usará el LLM para intentar un diagnóstico básico haciendo preguntas adicionales o interpretando mensajes de error descritos por el usuario. Si el problema persiste, el agente debe reconocer sus limitaciones y escalar la consulta (ej. \"No puedo resolver esto, por favor contacta con un agente humano en [enlace/teléfono]\").\n",
    "*   **Objetivos Principales:** Implementar un sistema RAG efectivo para Q&A, diseñar prompts para diálogo y diagnóstico simple, gestionar el flujo conversacional incluyendo la escalada.\n",
    "*   **Componentes Clave del Curso Aplicados:** RAG (Q&A sobre base de conocimiento), Ingeniería de Prompts (conversación, extracción de información), Lógica de Control (decisión basada en la salida de RAG).\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, Framework de Chatbot (Streamlit, Gradio), Vector DB, LLM API, LangChain.\n",
    "*   **Desafíos Potenciales:** Manejar preguntas ambiguas, asegurar que RAG recupere el contexto correcto, evitar que el LLM \"invente\" soluciones no presentes en la base de conocimientos, diseñar un flujo de escalada claro.\n",
    "*   **Entregable Sugerido:** Código fuente, la base de conocimientos utilizada (ej. archivos de texto), demo interactiva.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Generador de Itinerarios de Viaje Personalizado con Herramientas Simuladas\n",
    "\n",
    "*   **Descripción Detallada:** Este agente recibirá información del usuario: destino, fechas de viaje (o duración), intereses principales (ej. \"historia\", \"gastronomía\", \"senderismo\"), y un presupuesto aproximado (ej. \"bajo\", \"medio\", \"alto\"). Usando un LLM, el agente generará un borrador de itinerario día por día. El aspecto \"agencial\" se introduce al simular la interacción con herramientas externas: podría \"consultar\" una API de clima (simulada devolviendo datos aleatorios pero coherentes), una API de mapas (simulada para estimar tiempos de viaje entre lugares) o una API de eventos locales (simulada). Basándose en la información de estas \"herramientas\", el LLM refinará el itinerario (ej. sugiriendo actividades de interior si el \"clima\" es malo, o ajustando el orden de las visitas según los \"tiempos de viaje\").\n",
    "*   **Objetivos Principales:** Utilizar LLMs para generación creativa y estructurada, diseñar prompts complejos que incluyan preferencias y restricciones, simular el uso de herramientas por parte de un agente para refinar un plan.\n",
    "*   **Componentes Clave del Curso Aplicados:** Ingeniería de Prompts (instrucciones complejas, formato de salida), LLM (generación creativa y planificación), Sistemas Agenciales (concepto de uso de herramientas, ciclo planificar-ejecutar(simulado)-observar-replanificar).\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, LLM API, LangChain Agents (para gestionar el flujo con herramientas simuladas).\n",
    "*   **Desafíos Potenciales:** Generar itinerarios realistas y atractivos, manejar preferencias conflictivas, estructurar la salida de forma consistente, hacer que la interacción con herramientas simuladas sea significativa.\n",
    "*   **Entregable Sugerido:** Código fuente, demo interactiva donde se puedan variar los inputs y ver el itinerario generado y los logs de interacción (simulada) con herramientas.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Asistente de Programación con Contexto de Proyecto (RAG sobre Código)\n",
    "\n",
    "*   **Descripción Detallada:** El objetivo es crear una herramienta que ayude a programadores, yendo más allá de la simple generación de código aislada. El sistema permitirá al usuario \"cargar\" un pequeño proyecto de código (ej. varios archivos `.py`). Este código será procesado e indexado usando RAG (probablemente dividiéndolo en funciones o clases). Cuando el usuario haga una pregunta sobre el código (ej. \"¿Dónde se define la función X?\", \"¿Cómo puedo usar la clase Y?\") o pida generar nuevo código que interactúe con el existente (ej. \"Escribe una función que use la clase Z para hacer W\"), el sistema usará RAG para recuperar fragmentos relevantes del código del proyecto. Esta información contextual se incluirá en el prompt al LLM para generar una respuesta más precisa y adaptada al proyecto específico.\n",
    "*   **Objetivos Principales:** Aplicar RAG a un dominio no textual (código fuente), mejorar la calidad de la generación de código mediante la inclusión de contexto relevante, diseñar prompts específicos para tareas de programación con contexto.\n",
    "*   **Componentes Clave del Curso Aplicados:** RAG (indexación y recuperación de código), Ingeniería de Prompts (instrucciones de codificación contextualizadas), LLM (generación/explicación de código).\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, Vector DB, LLM API (especialmente modelos afinados para código como Code Llama o GPT-4), bibliotecas para parsear código (ej. `tree-sitter`), LangChain.\n",
    "*   **Desafíos Potenciales:** Estrategia efectiva para dividir (\"chunking\") y representar el código para RAG, manejar las limitaciones de contexto del LLM, asegurar la calidad y corrección del código generado.\n",
    "*   **Entregable Sugerido:** Código fuente de la herramienta, un proyecto de código de ejemplo, demo mostrando cómo responde a preguntas y genera código con contexto.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Sistema de Análisis de Sentimiento y Resumen de Reseñas de Productos\n",
    "\n",
    "*   **Descripción Detallada:** Este sistema tomará como entrada un conjunto de reseñas de texto sobre un producto (ej. extraídas de un archivo CSV o una lista de textos). Primero, utilizará un LLM (posiblemente con prompts zero-shot o few-shot) para clasificar el sentimiento (positivo, negativo, neutro) de cada reseña individual. Segundo, analizará el contenido de las reseñas (especialmente las positivas y negativas) para identificar temas o aspectos clave mencionados recurrentemente (ej. \"duración de la batería\", \"calidad de la pantalla\", \"servicio al cliente\"). Finalmente, generará un resumen conciso que destaque los principales puntos fuertes y débiles del producto según las reseñas. Opcionalmente, podría incluir una función basada en RAG que permita al usuario preguntar sobre aspectos específicos (ej. \"¿Qué dicen las reseñas sobre la cámara?\") y obtener un resumen enfocado.\n",
    "*   **Objetivos Principales:** Aplicar LLMs a tareas de NLP clásicas (clasificación de sentimiento, extracción de temas, resumen) de forma eficiente (zero/few-shot), estructurar un pipeline de análisis de texto.\n",
    "*   **Componentes Clave del Curso Aplicados:** Ingeniería de Prompts (clasificación, extracción, resumen), LLM (capacidades de procesamiento de lenguaje natural). RAG es opcional pero enriquecería el proyecto.\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, LLM API, Pandas (para manejar datos tabulares de reseñas).\n",
    "*   **Desafíos Potenciales:** Consistencia en la clasificación de sentimiento, identificación de temas relevantes vs. ruido, generación de resúmenes concisos pero informativos, manejo de lenguaje informal o irónico en las reseñas.\n",
    "*   **Entregable Sugerido:** Código fuente, un conjunto de datos de reseñas de ejemplo, los resultados del análisis (clasificaciones, temas, resumen), demo.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Agente de Curación de Noticias Personalizadas\n",
    "\n",
    "*   **Descripción Detallada:** El agente comenzará preguntando al usuario por sus temas de interés (ej. \"energías renovables\", \"inteligencia artificial\", \"exploración espacial\"). Periódicamente (o bajo demanda), el agente interactuará con una herramienta externa (una API de noticias real como NewsAPI, o un lector de feeds RSS) para obtener titulares y enlaces de artículos recientes sobre esos temas. Para evitar simplemente listar titulares, el agente utilizará RAG: descargará el contenido completo de los artículos más prometedores y usará RAG sobre este contenido para verificar que el artículo es realmente relevante y profundo sobre el tema de interés (no solo una mención superficial). Finalmente, para los artículos seleccionados, usará un LLM para generar un breve resumen (2-3 frases) y presentará al usuario un \"boletín\" personalizado con estos resúmenes y enlaces a los artículos originales.\n",
    "*   **Objetivos Principales:** Integrar un LLM con herramientas externas (APIs/RSS), usar RAG para un filtrado y análisis más profundo que la simple coincidencia de palabras clave, aplicar LLMs para la sumarización. Demostrar un ciclo agencial simple (definir objetivo -> buscar -> filtrar/analizar -> presentar).\n",
    "*   **Componentes Clave del Curso Aplicados:** Sistemas Agenciales (interacción con herramientas), RAG (análisis profundo de contenido recuperado), LLM (sumarización), Ingeniería de Prompts.\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, `requests`, `feedparser`, Vector DB (opcional, para RAG sobre artículos), LLM API, LangChain Agents.\n",
    "*   **Desafíos Potenciales:** Manejo de errores de API, volumen de artículos a procesar, efectividad del filtrado RAG, calidad y concisión de los resúmenes.\n",
    "*   **Entregable Sugerido:** Código fuente del agente, demo mostrando la generación de un boletín para un conjunto de temas.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Comparador de Políticas de Documentos (RAG Multi-Documento)\n",
    "\n",
    "*   **Descripción Detallada:** Este sistema permitirá al usuario cargar dos o más documentos largos y estructurados, como políticas de privacidad, términos de servicio o contratos simplificados (en formato PDF o TXT). El sistema procesará e indexará estos documentos usando RAG, manteniendo la referencia de qué fragmento pertenece a qué documento. Luego, el usuario podrá realizar preguntas comparativas, como \"¿Cuál es la política de reembolso en el documento A vs. documento B?\" o \"¿Hay diferencias en la cláusula de terminación?\". El sistema RAG recuperará las secciones relevantes de *cada* documento consultado. Un LLM recibirá estas secciones y la pregunta original, y tendrá la tarea de generar una respuesta que compare directamente las políticas, destacando similitudes y diferencias clave.\n",
    "*   **Objetivos Principales:** Implementar RAG capaz de manejar y referenciar múltiples fuentes simultáneamente, diseñar prompts efectivos para tareas de comparación y contraste basadas en texto recuperado.\n",
    "*   **Componentes Clave del Curso Aplicados:** RAG (indexación y recuperación multi-fuente), Ingeniería de Prompts (preguntas comparativas, síntesis comparativa), LLM (razonamiento sobre textos múltiples).\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, Vector DB (capaz de almacenar metadatos de origen), LLM API, biblioteca para leer PDFs.\n",
    "*   **Desafíos Potenciales:** Asegurar que RAG recupere las secciones *correspondientes* de cada documento para la comparación, la habilidad del LLM para realizar comparaciones precisas y evitar confusiones entre fuentes, manejo de lenguaje legal o técnico.\n",
    "*   **Entregable Sugerido:** Código fuente, documentos de ejemplo para comparar, demo interactiva respondiendo preguntas comparativas.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Planificador de Contenido para Redes Sociales\n",
    "\n",
    "*   **Descripción Detallada:** El usuario proporcionará un tema central, un enlace a un artículo de blog, o una idea general. El agente utilizará un LLM para generar múltiples propuestas de publicaciones cortas adaptadas a diferentes plataformas de redes sociales (ej. un tweet conciso y con hashtags, un post de LinkedIn más profesional y elaborado, una idea para una historia de Instagram). El prompt al LLM deberá especificar los requisitos de cada plataforma (longitud, tono, formato). Como mejora opcional, se podría implementar RAG sobre una colección de posts anteriores del usuario (si se proporcionan) para que el LLM intente mantener un estilo o tono de voz consistente con la marca personal o de la empresa.\n",
    "*   **Objetivos Principales:** Usar LLMs para generación de texto creativo y adaptativo, diseñar prompts que controlen múltiples aspectos de la salida (longitud, tono, formato, plataforma), opcionalmente aplicar RAG para consistencia de estilo.\n",
    "*   **Componentes Clave del Curso Aplicados:** Ingeniería de Prompts (instrucciones multi-plataforma, control de estilo), LLM (generación creativa). RAG es opcional.\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, LLM API.\n",
    "*   **Desafíos Potenciales:** Generar contenido que sea genuinamente atractivo y no genérico, lograr una diferenciación clara y apropiada entre las versiones para cada plataforma, mantener la consistencia de estilo si se implementa RAG.\n",
    "*   **Entregable Sugerido:** Código fuente, demo mostrando la generación de posts para diferentes inputs y plataformas.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Agente de Validación Preliminar de Ideas de Negocio\n",
    "\n",
    "*   **Descripción Detallada:** Un usuario introduce una breve descripción de una idea de negocio. El agente, potenciado por un LLM, inicia un diálogo \"socrático\": en lugar de dar una opinión directa, genera una serie de preguntas clave diseñadas para ayudar al usuario a reflexionar sobre su propia idea. Las preguntas cubrirían aspectos como: problema a resolver, mercado objetivo, propuesta única de valor, modelo de ingresos, competidores principales, etc. Opcionalmente, el agente podría simular el uso de herramientas: por ejemplo, al preguntar sobre competidores, podría decir \"Realizando una búsqueda simulada de competidores en [sector]...\" y luego usar el LLM para generar una lista plausible de tipos de competidores o empresas ficticias, basándose en la descripción de la idea. El objetivo final no es validar la idea, sino guiar al usuario a través de un proceso estructurado de pensamiento crítico inicial.\n",
    "*   **Objetivos Principales:** Utilizar LLMs para razonamiento estructurado y generación de preguntas relevantes, simular un proceso de consultoría o análisis básico, explorar el potencial de los LLMs en tareas de planificación y estrategia.\n",
    "*   **Componentes Clave del Curso Aplicados:** Ingeniería de Prompts (preguntas socráticas, análisis estructurado), LLM (razonamiento, generación de texto), Sistemas Agenciales (simulación de interacción con herramientas/búsqueda de información).\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, LLM API, LangChain (para gestionar el diálogo y la simulación de herramientas).\n",
    "*   **Desafíos Potenciales:** Generar preguntas que sean realmente perspicaces y no genéricas, mantener un flujo de conversación coherente, hacer que la simulación de herramientas aporte valor al proceso de reflexión.\n",
    "*   **Entregable Sugerido:** Código fuente del agente, demo interactiva mostrando el diálogo de validación para una idea de ejemplo.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Sistema RAG con Evaluación de Confianza Incorporada\n",
    "\n",
    "*   **Descripción Detallada:** El proyecto consiste en construir un sistema RAG estándar para responder preguntas sobre un corpus de documentos. La innovación clave es añadir una capa de evaluación de confianza. Después de que el LLM genere una respuesta basada en los fragmentos recuperados por RAG, el sistema debe realizar un paso adicional para estimar qué tan bien fundamentada está esa respuesta en la evidencia recuperada. Esto podría hacerse de varias maneras:\n",
    "    *   Mediante un prompt adicional al LLM: \"¿Basándote estrictamente en los siguientes fragmentos [fragmentos recuperados], evalúa en una escala de 1 a 5 qué tan directamente respaldan la siguiente afirmación [respuesta generada]? Explica tu razonamiento.\"\n",
    "    *   Mediante heurísticas: Calcular la similitud semántica entre la respuesta generada y los fragmentos recuperados, verificar si la respuesta contiene información no presente en los fragmentos (posible alucinación), etc.\n",
    "    El sistema final debería entregar no solo la respuesta, sino también esta puntuación o indicador de confianza y, idealmente, los fragmentos de evidencia que la respaldan.\n",
    "*   **Objetivos Principales:** Implementar un pipeline RAG completo, abordar el problema crítico de la confiabilidad y la \"fundamentación\" (grounding) en RAG, experimentar con técnicas de evaluación de la salida del LLM.\n",
    "*   **Componentes Clave del Curso Aplicados:** RAG (completo), LLM (generación y evaluación), Ingeniería de Prompts (para la evaluación de confianza), Métricas y Evaluación (concepto de confiabilidad).\n",
    "*   **Posibles Herramientas/Tecnologías:** Python, Vector DB, LLM API, bibliotecas de cálculo de embeddings/similitud (ej. `sentence-transformers`).\n",
    "*   **Desafíos Potenciales:** Definir una métrica de confianza significativa, diseñar prompts o heurísticas fiables para la autoevaluación, evitar que el LLM sobreestime su propia confianza, presentar la información de confianza de manera útil al usuario.\n",
    "*   **Entregable Sugerido:** Código fuente del sistema RAG con evaluación de confianza, corpus de ejemplo, demo mostrando respuestas con sus puntuaciones de confianza y justificaciones, informe explicando el método de evaluación de confianza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342de87-970d-4bdb-9fda-05bff9408d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
